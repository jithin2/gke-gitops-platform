apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: platform-alerts
  namespace: monitoring
  labels:
    release: monitoring
spec:
  groups:
    # ------------------------------------------------------------------
    # Pod Health Alerts
    # ------------------------------------------------------------------
    - name: pod-health
      rules:
        - alert: PodCrashLooping
          expr: rate(kube_pod_container_status_restarts_total{namespace=~"dev|staging|production"}[15m]) > 0
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "Pod {{ $labels.pod }} is crash looping"
            description: "Pod {{ $labels.pod }} in {{ $labels.namespace }} has restarted {{ $value }} times in the last 15 minutes"
            runbook: "https://github.com/YOUR_ORG/gke-gitops-platform/blob/main/docs/TROUBLESHOOTING-GUIDE.md#crashloopbackoff"

        - alert: PodNotReady
          expr: kube_pod_status_ready{namespace=~"dev|staging|production", condition="true"} == 0
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: "Pod {{ $labels.pod }} is not ready"
            description: "Pod {{ $labels.pod }} in {{ $labels.namespace }} has been not ready for more than 10 minutes"

        - alert: ContainerOOMKilled
          expr: kube_pod_container_status_last_terminated_reason{reason="OOMKilled", namespace=~"dev|staging|production"} == 1
          for: 0m
          labels:
            severity: critical
          annotations:
            summary: "Container {{ $labels.container }} was OOM killed"
            description: "Container {{ $labels.container }} in pod {{ $labels.pod }} was terminated due to OOM"

    # ------------------------------------------------------------------
    # Resource Alerts
    # ------------------------------------------------------------------
    - name: resource-alerts
      rules:
        - alert: HighCPUUsage
          expr: |
            sum(rate(container_cpu_usage_seconds_total{namespace=~"dev|staging|production"}[5m])) by (pod, namespace)
            / sum(kube_pod_container_resource_limits{resource="cpu", namespace=~"dev|staging|production"}) by (pod, namespace) > 0.9
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: "Pod {{ $labels.pod }} CPU usage above 90%"

        - alert: HighMemoryUsage
          expr: |
            sum(container_memory_working_set_bytes{namespace=~"dev|staging|production"}) by (pod, namespace)
            / sum(kube_pod_container_resource_limits{resource="memory", namespace=~"dev|staging|production"}) by (pod, namespace) > 0.85
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: "Pod {{ $labels.pod }} memory usage above 85%"

        - alert: PVCAlmostFull
          expr: kubelet_volume_stats_used_bytes / kubelet_volume_stats_capacity_bytes > 0.85
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "PVC {{ $labels.persistentvolumeclaim }} is 85% full"

    # ------------------------------------------------------------------
    # SLA / Availability Alerts
    # ------------------------------------------------------------------
    - name: sla-alerts
      rules:
        - alert: HighErrorRate
          expr: |
            sum(rate(http_requests_total{status=~"5..", namespace=~"dev|staging|production"}[5m])) by (service)
            / sum(rate(http_requests_total{namespace=~"dev|staging|production"}[5m])) by (service) > 0.05
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "Service {{ $labels.service }} error rate above 5%"
            description: "The 5xx error rate for {{ $labels.service }} is {{ $value | humanizePercentage }}"

        - alert: HighLatencyP99
          expr: histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)) > 2
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: "Service {{ $labels.service }} P99 latency above 2s"

    # ------------------------------------------------------------------
    # Node Alerts
    # ------------------------------------------------------------------
    - name: node-alerts
      rules:
        - alert: NodeNotReady
          expr: kube_node_status_condition{condition="Ready", status="true"} == 0
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "Node {{ $labels.node }} is not ready"

        - alert: NodeDiskPressure
          expr: kube_node_status_condition{condition="DiskPressure", status="true"} == 1
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "Node {{ $labels.node }} has disk pressure"
